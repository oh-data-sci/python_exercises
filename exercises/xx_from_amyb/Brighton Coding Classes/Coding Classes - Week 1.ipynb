{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Coding Classes - Week 1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Iwpy03hHZTRP","colab_type":"text"},"cell_type":"markdown","source":["# Scraping the text from a webpage and creating a topic cloud"]},{"metadata":{"id":"QEb_WIPEZTRQ","colab_type":"text"},"cell_type":"markdown","source":["## Import Statements"]},{"metadata":{"id":"fTqLT7pmZTRS","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","In python you can _import_ pieces of other people's code or _modules_. \n","\n","Here we're importing a piece of code that someone else already wrote for us.  Kind of like the Brandwatch API SDK, the wikipedia module is just a wrapper that makes it easier to access Wikipedia's API.  Similarly, mechanicalsoup is a bunch of code that someone else wrote that makes grabbing the text from a webpage very easy. \n","\n","For more info on the Wikipedia module read this: https://wikipedia.readthedocs.io/en/latest/\n","\n","This for BeautifulSoup (parent of MechanicalSoup): http://beautiful-soup-4.readthedocs.io/en/latest/\n","\n","\n","Importing modules is great because it means we don't have to write that code ourselves!"]},{"metadata":{"id":"DElCsWlNZb0M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"464d84af-be26-4c94-c26b-b9193ebc4b97","executionInfo":{"status":"ok","timestamp":1555076687896,"user_tz":-60,"elapsed":16429,"user":{"displayName":"Alastair Lockie","photoUrl":"https://lh5.googleusercontent.com/-PDrY4BsH4Us/AAAAAAAAAAI/AAAAAAAAAH0/Kg3eTrY8axA/s64/photo.jpg","userId":"09836200609143402066"}}},"cell_type":"code","source":["!pip install wikipedia\n","!pip install mechanicalsoup\n","!pip install matplotlib\n","!pip install wordcloud"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.18.4)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.3.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.6)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n","Collecting mechanicalsoup\n","  Downloading https://files.pythonhosted.org/packages/f6/6a/263f3e12d50e3272abf3842e13a3c991cda4af0f253e9c73a41d0b8387c3/MechanicalSoup-0.11.0-py2.py3-none-any.whl\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from mechanicalsoup) (2.18.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from mechanicalsoup) (4.6.3)\n","Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.6/dist-packages (from mechanicalsoup) (1.11.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from mechanicalsoup) (4.2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->mechanicalsoup) (1.22)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->mechanicalsoup) (2.6)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->mechanicalsoup) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->mechanicalsoup) (2019.3.9)\n","Installing collected packages: mechanicalsoup\n","Successfully installed mechanicalsoup-0.11.0\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.9.0)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (1.5.0)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud) (1.14.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud) (4.1.1)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud) (0.46)\n"],"name":"stdout"}]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:34.894749Z","start_time":"2018-04-24T10:56:34.739659Z"},"id":"2sUCi5QRZTRS","colab_type":"code","colab":{}},"cell_type":"code","source":["import wikipedia\n","from mechanicalsoup import Browser\n","\n","mech = Browser()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nLyBhH1hZTRW","colab_type":"text"},"cell_type":"markdown","source":["Now we can use that wikipedia module to search Wikipedia for a page - let's say Brandwatch's page.\n","\n","The following line is exactly the same as using the 'search' bar on the Wikipedia page to look for Brandwatch."]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:35.178631Z","start_time":"2018-04-24T10:56:34.896848Z"},"id":"2VGTfiHIZTRX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b8426cd4-5543-47e9-f77d-56c95ed1acd0","executionInfo":{"status":"ok","timestamp":1555077148356,"user_tz":-60,"elapsed":720,"user":{"displayName":"Alastair Lockie","photoUrl":"https://lh5.googleusercontent.com/-PDrY4BsH4Us/AAAAAAAAAAI/AAAAAAAAAH0/Kg3eTrY8axA/s64/photo.jpg","userId":"09836200609143402066"}}},"cell_type":"code","source":["wikipedia.search(\"buzzsumo\")"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Nostalgia industry', 'Brandwatch']"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"DHbM6CGLZTRc","colab_type":"text"},"cell_type":"markdown","source":["Now let's use a _variable_ to save that information somewhere.  A variable is kind of like a label. \n","\n","Here we're creating a variable (or label) 'bw' and storing all the data with that label.  This is useful because we can refer to that data later with just the symbol bw instead of that whole big messy text."]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:35.685718Z","start_time":"2018-04-24T10:56:35.181018Z"},"id":"jU42G3oQZTRd","colab_type":"code","colab":{}},"cell_type":"code","source":["bw = wikipedia.page(\"Brandwatch\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-6PaBQY2ZTRf","colab_type":"text"},"cell_type":"markdown","source":["New variables often inherit attributes from the type of data they are storing. In this case the bw variable inherits a few useful functions from the command above. If you place your cursor after the period in bw and hit <tab> you can see what functions the variable has. \n","\n","Let's see what's in the bw.summary\n"]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:35.901810Z","start_time":"2018-04-24T10:56:35.688222Z"},"id":"uOpQLzITZTRg","colab_type":"code","colab":{}},"cell_type":"code","source":["bw.summary"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T-HSpKMwZTRj","colab_type":"text"},"cell_type":"markdown","source":["If you looked at a few of the functions you might notice a few useful ones. We're going to need the URL of the webpage later so let's store that in another variable so we can use it later"]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:35.906694Z","start_time":"2018-04-24T10:56:35.904047Z"},"id":"Q81l_RM3ZTRk","colab_type":"code","colab":{}},"cell_type":"code","source":["#Grab the URL of the Brandwatch page and assign it to the variable \"url\"\n","url = bw.url"],"execution_count":0,"outputs":[]},{"metadata":{"id":"o5t4IdZGZTRm","colab_type":"text"},"cell_type":"markdown","source":["## Let's grab the text from the webpage!\n","\n","We've got everything we need to tell MechanicalSoup to crawl a webpage a give us some data!\n","\n","Remember in the first cell where we set the Browser function from mechanicalsoup to mech? We're going to use that now.\n","\n","mech is going to _get_ everything from the url we picked, in this case the Brandwatch homepage.\n","\n","Then its going to find everything inside the _p_ brackets on an html page and put that data into the variable match. We're going to do the exact same thing for titles."]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:35.998652Z","start_time":"2018-04-24T10:56:35.909279Z"},"id":"pAQQbYXzZTRn","colab_type":"code","colab":{}},"cell_type":"code","source":["#Crawl the url and pull out all the text\n","\n","page = mech.get(url)\n","matches = page.soup.select(\"p\")\n","matches2 = page.soup.select(\"title\")\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"57OqbugRZTRq","colab_type":"text"},"cell_type":"markdown","source":["This part is a little bit of housekeeping, but we're going to drop all the html markup and keep only the text. Then we're going to store it in a text file and keep it for later. File I/O, or input/output is super useful! \n","\n","You read more about how to do that in Python here:https://docs.python.org/3/tutorial/inputoutput.html\n"]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:36.006684Z","start_time":"2018-04-24T10:56:36.001523Z"},"id":"1UDyH7VeZTRr","colab_type":"code","colab":{}},"cell_type":"code","source":["#Drop everything into a text file\n","f = open('workfile', 'w')\n","line=u''\n","# Paragraphs\n","for match in matches:\n","    f.write(match.getText())\n","# Titles\n","for match in matches2:\n","    f.write(match.getText())\n","    f.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KA2M3w3MZTRt","colab_type":"text"},"cell_type":"markdown","source":["## Time for the fun stuff! Wordclouds!\n","\n","Let's grab a couple more modules, this time Wordcloud to make the topic clouds, and matplotlib for displaying the data\n","\n","After we get everything imported we're going to read the text file we made earlier and store all the words in a variable. \n","\n","Next all we have to do if generate the wordcloud and plot it. Don't worry if you don't get how I knew _that_ was the way to use the function. Part of learning how to use new functions is about reading documentation. These files are usually online and can range from incredibly informative with lots of examples to very technical and hard to understand finally to just non-existant. Don't worry, figuring out how to be an expert Googler is all part of learning how to write code\n","\n"]},{"metadata":{"ExecuteTime":{"end_time":"2018-04-24T10:56:37.231760Z","start_time":"2018-04-24T10:56:36.009532Z"},"id":"lvbu2_G9ZTRu","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","\n","from wordcloud import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","\n","# Read the file in and merge all lines\n","words=' '\n","f = open('workfile', 'r')\n","for line in f:\n","    words = words + line\n","f.close\n"," \n","# Make the word cloud (I use a font that I like)\n","wordcloud = WordCloud().generate(words)\n","\n","plt.imshow(wordcloud)\n","plt.axis('off')\n","plt.savefig('./cloud2.png', dpi=300)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iG-OFAXjZTRx","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","###### We hope this was a good introduction to learning about writing code! Can't wait to see you all next week!\n","\n","###### Cheers!\n","###### Paul, Amy and Ian"]}]}