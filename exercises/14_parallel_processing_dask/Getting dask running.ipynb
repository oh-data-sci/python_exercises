{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting dask running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `dask` in a distributed way requires three components:\n",
    "\n",
    "1. _worker_ processes to do the computation\n",
    "2. a _scheduler_ process to coordinate the computation, by allocating (sub)tasks to workers, and moving data and results around\n",
    "3. a _client_ to submit tasks to be carried out\n",
    "\n",
    "To give your computations some _ooomph_, run the workers and scheduler on a powerful instance on EC2 or OpenStack. You can run the client on that instance too, or on your laptop if that's more convenient. These instructions assume you're running it on your laptop. You can also add more EC2 or OpenStack instances for additional workers, if you need even more _ooomph_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the instance for the workers and scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created an image on OpenStack called `ubuntu-18.04-python-3.7.0-dask` and an AMI on EC2 with the same name. The username for these is `ubuntu` rather than the `ec2-user` that you might be used to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log into your instance with `ssh`, and do port forwarding for ports 8786 and 8787 at the same time:\n",
    "\n",
    "    ssh -L 8786:localhost:8786 -L 8787:localhost:8787 ubuntu@10.2.16.165\n",
    "\n",
    "Port 8786 is for the workers and client will connect to the scheduler. Port 8786 is for the scheduler's web dashboard.\n",
    "\n",
    "On your instance run\n",
    "\n",
    "    cd dask_stuff\n",
    "    pipenv run dask-scheduler\n",
    "\n",
    "The scheduler will start and give you a message like this:\n",
    "\n",
    "    distributed.scheduler - INFO - -----------------------------------------------\n",
    "    distributed.scheduler - INFO - Clear task state\n",
    "    distributed.scheduler - INFO -   Scheduler at:    tcp://172.16.0.27:8786\n",
    "    distributed.scheduler - INFO -       bokeh at:                     :8787\n",
    "    distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-41ssh763\n",
    "    distributed.scheduler - INFO - -----------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the web dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now open the web dashboard by going here [http://localhost:8787](http://localhost:8787)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With another `ssh` session, or using `screen` or `tmux` magic, run something like following:\n",
    "\n",
    "    cd dask_stuff/dask_workers\n",
    "    pipenv run dask-worker --nprocs 12 --nthreads 1 172.16.0.27:8786 --memory-limit 4GB\n",
    "\n",
    "Note the following parts of the command:\n",
    "\n",
    "- the `nprocs` part determines how many worker processes will be started\n",
    "- the `nthreads` part determines how many threads will run within each worker process (I would suggest just setting this to 1, because of python's Global Interpreter Lock bollocks)\n",
    "- the IP and port number `172.16.0.27:8786` need to match what the scheduler output when it was started (and if you want to run additional workers on additional instances, this is how they will know where the scheduler is)\n",
    "- the `memory-limit` part sets how much memory each worker process is allocated\n",
    "\n",
    "On the scheduler's stdout you will see a message like this for each worker that joins:\n",
    "\n",
    "    distributed.scheduler - INFO - Register tcp://172.16.0.27:37375\n",
    "    distributed.scheduler - INFO - Starting worker compute stream, tcp://172.16.0.27:37375\n",
    "    distributed.core - INFO - Starting established connection\n",
    "\n",
    "You can also check in the \"Workers\" tab of the web dashboard, to see your lovely workers read to work for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're now ready to start a client and do some work. You can run the client on your own laptop, where you can install `dask` like this:\n",
    "\n",
    "    pipenv install \"dask[complete]\"\n",
    "\n",
    "Try to have the same versions of python and `dask` on the different machines. One thing I have found that definitely caused problems was trying to mix machines running python 3.6.something with machines running python 3.7.something. (This is why the AMI I've made contains a python 3.7.0 built from source.)\n",
    "\n",
    "\n",
    "The other example notebooks included will show you how to run a client :) Happy `dask`ing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
