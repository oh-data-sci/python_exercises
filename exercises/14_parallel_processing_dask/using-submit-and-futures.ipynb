{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple use of `dask` with `submit` and Future objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the basic mechanism for using `dask` for distributed computation. We will see how to submit tasks for execution on a cluster, and how to get the results back.\n",
    "\n",
    "**`dask` also provides various higher-level APIs built on top of these foundations, such as distributed data frames and distributed bags. These are great but we won't look at those in this notebook; if people are interested in these, we will have to do them another week.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `dask` in a distributed way requires three components:\n",
    "\n",
    "1. _worker_ processes to do the computation\n",
    "2. a _schedular_ process to coordinate the computation, by allocating (sub)tasks to workers, and moving data and results around\n",
    "3. a _client_ to submit tasks to be carried out\n",
    "\n",
    "For this demo, I have started worker and scheduler processes on an openstack instance; the client will be this notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('127.0.0.1:8786')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see some information about the resources available to the scheduler, and a link to a dashboard page that will allow us to monitor the execution of our tasks in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a naive function for primality testing, that will nevertheless enable us to create non-trivial amounts of CPU work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, floor\n",
    "\n",
    "def is_prime(n):\n",
    "    \n",
    "    if n < 2:\n",
    "        return False\n",
    "    \n",
    "    if n == 2:\n",
    "        return True\n",
    "    \n",
    "    for i in range(floor(sqrt(n)) + 1):\n",
    "        if i > 1 and n % i == 0:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def count_primes_less_than(m):  # Count number of primes less than input n\n",
    "    return sum([is_prime(i) for i in range(m)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this implementation is stupid enough to generate quite long running times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count_primes_less_than(5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of running this on our local machine, we can ask `dask` to compute it on the cluster using the `submit` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = client.submit(count_primes_less_than, 5000000)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we get back is a _Future_, which is an object that represents the result of a task we've launched. Currently the status of the Future is **pending**, meaning that the computation is running. When the task is finished and the result value is ready, the status will become **finished**. Futures can also have the status **error** if something went wrong, plus a couple of others e.g. **cancelled** if you cancel the task before it completes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Future has the **finished** state, you can call its `result` method to get the actual result value out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `submit`, the `result()` method is _synchronous_: if you call `result` before the result is ready, the call will simply block until it is ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = client.submit(count_primes_less_than, 5000001)\n",
    "print(M.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `submit` call is _eager_ - the scheduler will start the submitted task running on the cluster as soon it can. It is also possible to start tasks in a _lazy_ way, so that they don't start running until a later processing stage needs their output, but we won't cover that in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running stuff in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far you might have been wondering what the point of `dask` is - what does it get us? One answer is that if we have many worker processes, running on a powerful computer or across several powerful computers, we can **run things in parallel**.\n",
    "\n",
    "The `map` method is like `submit`, but we can give a whole list or iterable of arguments, and one task will be create for each one. The scheduler will run these in parallel where possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(count_primes_less_than, range(3000001, 3000010))\n",
    "futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tasks complete, we'll see that some of these Futures start to get the **finished** status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can save a massive amount of time.\n",
    "\n",
    "Let's do some timing to prove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_test():\n",
    "    for i in range(9):\n",
    "        print(count_primes_less_than(1500000 + i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "local_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_test():\n",
    "    futures = client.map(count_primes_less_than, [1500000 + i for i in range(9)])\n",
    "    print(futures)\n",
    "    results = client.gather(futures)\n",
    "    for r in results:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distributed_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `gather` used in the above is like `result` but used for getting results from a whole list of Futures as one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining together tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as taking regular value arguments, `.submit` can take Futures as well. In this case the submitted computation will start running as soon as all the required arguments are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_them(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = client.submit(count_primes_less_than, 4000000)\n",
    "M2 = client.submit(count_primes_less_than, 4500000)\n",
    "\n",
    "Msum = client.submit(add_them, M1, M2)\n",
    "Msum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msum.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, if we want to we can **build up a whole DAG of computation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3 = client.submit(count_primes_less_than, 4000003)\n",
    "M4 = client.submit(count_primes_less_than, 4500004)\n",
    "M5 = client.submit(count_primes_less_than, 4000005)\n",
    "M6 = client.submit(count_primes_less_than, 4500006)\n",
    "M7 = client.submit(count_primes_less_than, 4000007)\n",
    "M8 = client.submit(count_primes_less_than, 4500008)\n",
    "\n",
    "Msum1 = client.submit(add_them, M3, M4)\n",
    "Msum2 = client.submit(add_them, M5, M6)\n",
    "Msum3 = client.submit(add_them, M7, M8)\n",
    "\n",
    "Msum4 = client.submit(add_them, Msum1, Msum2)\n",
    "Msum5 = client.submit(add_them, Msum4, Msum3)\n",
    "\n",
    "Msum6 = client.submit(add_them, M3, Msum3)\n",
    "\n",
    "K = Msum5.result()\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about when things go wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an error occurs while executing a task on the cluster, the Future object gets status **error**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goes_wrong():\n",
    "    return 10 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = client.submit(goes_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such cases, if we try to get the result value with `.result()` we will get the traceback for the error! Yay, it's just a python traceback of the kind we are used to by now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restarting things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If things somehow go irredeemably pear-shaped, you can get back to a clean state in the scheduler and workers like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
